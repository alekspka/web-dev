# Using LLM – Part 2

> [!NOTE]
>  This is the second in a two‑part series on using the Gemini LLM. This part covers analyzing images, audio, and documents. [Part 1](https://github.com/tx00-resources-en/AI-part1) focuses on text generation with both static and dynamic prompts, and on receiving structured responses.

---

## TOC

- [Step 0: Prerequisites](#step-0-prerequisites)
- [Step 1: Setup Instructions](#step-1-setup-instructions)
- [Step 2: Testing the Endpoints with Postman](#step-2-testing-the-endpoints-with-postman)
- [Step 3: Model Configuration](#step-3-model-configuration)
- [Code Reference: Generate Text](#code-reference-generate-text)
- [Code Reference: `App.js`](#code-reference-appjs)
- [Code Reference: Analyze Image](#code-reference-analyze-image)
- [Code Reference: Analyze Document](#code-reference-analyze-document)
- [Code Reference: Analyze Audio](#code-reference-analyze-audio)
 
---

## Step 0: Prerequisites

- **Gmail Account** – Create a personal Gmail account if you don’t already have one.
- **API Key** – Generate one at [Google AI Studio](https://aistudio.google.com/app/apikey) and store it somewhere safe.

---

## Step 1: Setup Instructions

1. **Clone the repository**  
   ```bash
   git clone https://github.com/tx00-resources-en/AI-part2
   cd AI-part2
   ```

2. **Remove Git history**  
   ```bash
   rm -rf .git
   ```

3. **Configure environment variables**  
   - Open `.env.example`  
   - On **line 1**, replace the dummy key  
     ```
     Jh6AIvfYH87KKL34KllmsHg
     ```  
     with the API key you generated earlier.
   - Rename the file:  
     ```bash
     mv .env.example .env
     ```

4. **Install dependencies**  
   ```bash
   npm install
   ```

5. **Start the development server**  
   ```bash
   npm run dev
   ```

---

## Step 2: Testing the Endpoints with Postman

### **Generate Text**
**Endpoint:**  
```
POST http://localhost:4000/generate-text
```
**Body (raw JSON):**
```json
{
  "prompt": "Write 3 practical tips for staying productive while working from home."
}
```
**Expected:**  
A text response generated by the Gemini LLM.¨

- You can modify prompts in the request body to experiment with different outputs.

### **Analyze Image**
**Endpoint:**  
```
POST http://localhost:4000/analyze-image
```
**Body (form-data):**
- **Key:** `image` (type: *File*)  
- **Value:** Select an image file from your local machine.  
  > **Important:** For file uploads (image, audio, document), make sure the files are stored somewhere accessible on your machine — for example: `C:\Users\<your-username>\Postman\files` Replace `<your-username>` with your actual Windows username.  When selecting the file in Postman, navigate to this directory.

**Expected:**  
A description or analysis of the uploaded image from the Gemini LLM.


### **Analyze Audio**
**Endpoint:**  
```
POST http://localhost:4000/analyze-audio
```
**Body (form-data):**
- **Key:** `audio` (type: *File*)  
- **Value:** Select an audio file (e.g., `.mp3`, `.wav`) from your local machine.
  > **Important:** For file uploads (image, audio, document), make sure the files are stored somewhere accessible on your machine — for example: `C:\Users\<your-username>\Postman\files` Replace `<your-username>` with your actual Windows username.  When selecting the file in Postman, navigate to this directory.
  
**Expected:**  
A transcription, summary, or analysis of the audio content.


### **Analyze Document**
**Endpoint:**  
```
POST http://localhost:4000/analyze-document
```
**Body (form-data):**
- **Key:** `document` (type: *File*)  
- **Value:** Select a document file (e.g., `.pdf`, `.txt`) from your local machine.
  > **Important:** For file uploads (image, audio, document), make sure the files are stored somewhere accessible on your machine — for example: `C:\Users\<your-username>\Postman\files` Replace `<your-username>` with your actual Windows username.  When selecting the file in Postman, navigate to this directory.

**Expected:**  
Extracted text, summary, or structured analysis of the document.


### Notes
- For **file uploads** (image, audio, document), always use **form-data** in Postman and set the key type to **File**.
- The backend will handle sending the uploaded file to Gemini for processing.

---

## Step 3: Model Configuration

- **Temperature** controls randomness in output:  
  - `0.0` → Deterministic  
  - `0.7–1.0` → More random, creative responses  
- Current setting:  
  ```js
  config: {
    temperature: 0.1, // Low randomness, focused and consistent
  }
  ```
---

## Code Reference: Generate Text

> For details on the text generation code, see [part 1](https://github.com/tx00-resources-en/AI-part1)


---

## Code Reference: `App.js`

To enable the server to **receive and process uploaded files** (such as images, audio, or documents), we use the **Multer** middleware in our Express app.

1. **Install and import Multer**  
   - In `App.js` (line 3), import Multer after installing it with:  
     ```bash
     npm install multer
     ```

2. **Create an uploads folder**  
   - In `App.js` (lines 20–23), check if an `uploads` directory exists.  
   - If it doesn’t, create it. This is where Multer will store uploaded files.

3. **Configure Multer**  
   - In `App.js` (line 26), create a Multer instance and set its `dest` option to the `uploads` folder.

**Code Explanation**

```js
const multer = require('multer'); // Import Multer middleware
const fs = require('fs');         // Node.js file system module
const path = require('path');     // Node.js path utility

// 1. Define the uploads folder path
const uploadDir = path.join(__dirname, 'uploads');

// 2. Check if the folder exists; if not, create it
if (!fs.existsSync(uploadDir)) {
    fs.mkdirSync(uploadDir);
}

// 3. Create a Multer instance configured to store files in the uploads folder
const upload = multer({ dest: uploadDir });
```


**Step-by-step**
- **`multer`**: Middleware that handles `multipart/form-data` — the encoding type used for file uploads in HTML forms.
- **`fs.existsSync(uploadDir)`**: Checks if the `uploads` folder already exists.
- **`fs.mkdirSync(uploadDir)`**: Creates the folder if it doesn’t exist.
- **`multer({ dest: uploadDir })`**: Tells Multer to store uploaded files in the `uploads` directory with automatically generated filenames.


**What is Multer?**

Multer is an Express middleware for handling `multipart/form-data`, which is primarily used for **file uploads**.  
When dealing with **images, audio, or documents**:
- It parses incoming form data that contains files.
- It temporarily stores those files in a specified location (in this case, `uploads/`).
- It makes the file information available in `req.file` (for single uploads) or `req.files` (for multiple uploads) so you can process them further — e.g., save to cloud storage, analyze content, or serve back to the client.

**Example usage in a route:**
```js
app.post('/analyze-image', upload.single('image'),analyzeImage);
```


**In short:**  
- **Multer** handles the heavy lifting of parsing and storing uploaded files.  
- **The `uploads` folder** is where those files are saved temporarily.  
- **This setup** works for any file type — images, audio, PDFs, Word docs, etc.

---

## Code Reference: Analyze Image

When we want to analyse an image using a Large Language Model (LLM) like Gemini, we need to send both:
1. A **prompt** (text instructions telling the model what to do).
2. The **image data** in a format the model can understand.

The [`imageController.js`](./controllers/imageController.js) file contains two main parts that make this possible: `imageToGenerativePart` and `analyzeImage`.

**1. `imageToGenerativePart(filePath)`**

```js
const imageToGenerativePart = (filePath) => ({
    inlineData: {
      data: fs.readFileSync(filePath).toString('base64'),
      mimeType: 'image/png',
    },
})
```

**Purpose:**  
This helper function prepares the uploaded image so it can be sent to the LLM.

**What it does:**
- **Reads the file** from the server using `fs.readFileSync(filePath)`.
- **Encodes it in Base64** with `.toString('base64')`.  
  Base64 turns binary image data into text so it can be sent in a JSON request.
- **Adds the MIME type** (`image/png`) so the LLM knows the file format.
- Returns an object in the format the Gemini API expects for inline image input.

**2. `analyzeImage(req, res)`**

```js
const analyzeImage = async (req, res) => {
    const prompt = req.body.prompt || 'Describe this image';
    const filePath = req.file?.path;

    try {
        const image = imageToGenerativePart(filePath);
        const result = await model([prompt, image]);
        res.json({ output: result.text });
    } catch (error) {
        res.status(500).json({ error: error.message });
    } finally {
        if (filePath && fs.existsSync(filePath)) {
            fs.unlinkSync(filePath);
        }
    }
};
```

**Step-by-step:**
- **Get the prompt**  
   - Uses the prompt from the request body, or defaults to `"Describe this image"`.

- **Get the uploaded file path**  
   - `req.file?.path` is set by Multer when the file is uploaded.

- **Convert the image**  
   - Calls `imageToGenerativePart(filePath)` to prepare the image for the LLM.

- **Send to the LLM**  
   - `await model([prompt, image])` sends both the text prompt and the image data to Gemini.
   - The model processes them together and generates a text response.

- **Return the result**  
   - Sends the model’s output back to the client as JSON.

- **Clean up**  
   - Deletes the uploaded file from the server after processing.

**3. Role of Multer**

Before this controller runs, **Multer** (an Express middleware) handles the file upload:
- Parses `multipart/form-data` requests.
- Saves the uploaded file to the `uploads/` folder.
- Adds file details (including `.path`) to `req.file`.

Without Multer, the server wouldn’t have access to the uploaded image file.

**4. Why This Works**
- The LLM is **multimodal** — it can process both text and images.
- By passing `[prompt, image]`, we give it **instructions** and **visual content** at the same time.
- This allows for many use cases:
  - Describing an image
  - Identifying objects
  - Extracting text from an image
  - Analysing design or style
  - Giving recommendations based on the image


---

## Code Reference: Analyze Document

When we want to analyse a document (PDF, Word file, text file, etc.) using a Large Language Model (LLM) like Gemini, we need to send:

1. A **prompt** (text instructions telling the model what to do).  
2. The **document data** in a format the model can process.

The [`documentController.js`](./controllers/documentController.js) file contains the logic to:
- Read the uploaded document from disk.
- Convert it into a Base64‑encoded format.
- Send it to the LLM along with a prompt.
- Return the model’s output to the client.
- Clean up the uploaded file.

**1. Checking for an Uploaded File**

```js
if (!filePath) {
    return res.status(400).json({ error: 'No document uploaded' });
}
```
- Uses optional chaining (`req.file?.path`) to safely check if a file was uploaded.
- If no file is found, responds with a `400 Bad Request` error.

**2. Reading and Encoding the Document**

```js
const buffer = fs.readFileSync(filePath);
const base64Doc = buffer.toString('base64');
const mimeType = req.file.mimetype;
```
- **`fs.readFileSync(filePath)`**: Reads the document file from disk into a buffer (binary data).
- **`.toString('base64')`**: Converts the binary data into a Base64 string so it can be sent in a JSON request.
- **`mimeType`**: Comes from `req.file.mimetype` (set by Multer) and tells the LLM the file type (e.g., `application/pdf`, `application/msword`, `text/plain`).

**3. Creating the Document Input Object**

```js
const documentPart = {
    inlineData: {
        data: base64Doc,
        mimeType
    }
};
```
- **`inlineData.data`**: Contains the Base64‑encoded document.
- **`mimeType`**: Informs the LLM of the document’s format so it can process it correctly.

**4. Sending the Prompt and Document to the LLM**

```js
const result = await model([
    'Analyse this document:',
    documentPart
]);
```
- The first array element is the **prompt** — here it’s a generic instruction to analyse the document.
- The second element is the **document data object**.
- Passing both together allows the LLM to process the document in the context of the prompt.


**5. Returning the Result**

```js
res.json({ output: result.text });
```
- The LLM’s response is returned to the client as JSON.
- `result.text` contains the analysis generated by the model.

**6. Cleaning Up**

```js
if (filePath && fs.existsSync(filePath)) {
    fs.unlinkSync(filePath);
}
```
- After processing, the uploaded file is deleted from the server to save space and avoid clutter.

**7. Role of Multer**

Before this controller runs:
- **Multer** handles the file upload from the client.
- It saves the file to the `uploads/` folder.
- It adds file details (including `.path` and `.mimetype`) to `req.file`, which this controller uses.

**Why This Works**
- The LLM can process both text and non‑text inputs (multimodal capability).
- By sending a **prompt** and the **document data** together, we can:
  - Summarise the document.
  - Extract key points.
  - Identify topics or entities.
  - Answer questions based on the document’s content.

---

## Code Reference: Analyze Audio

When we want to analyse or transcribe an audio file using a Large Language Model (LLM) like Gemini, we need to send:

1. A **prompt** (text instructions telling the model what to do).  
2. The **audio data** in a format the model can process.

The [`audioController.js`](./controllers/audioController.js) file contains the logic to:
- Read the uploaded audio file.
- Convert it into a Base64‑encoded format.
- Send it to the LLM along with a prompt.
- Return the model’s output to the client.
- Clean up the uploaded file.

**1. Reading and Encoding the Audio**

```js
const audioBuffer = fs.readFileSync(filePath);
const base64Audio = audioBuffer.toString('base64');
```
- **`fs.readFileSync(filePath)`**: Reads the audio file from disk into a buffer (binary data).
- **`.toString('base64')`**: Converts the binary data into a Base64 string so it can be sent in a JSON request.

**2. Creating the Audio Input Object**

```js
const audioPart = {
    inlineData: {
        data: base64Audio,
        mimeType: req.file.mimetype
    }
};
```
- **`inlineData.data`**: Contains the Base64‑encoded audio.
- **`mimeType`**: Comes from `req.file.mimetype` (set by Multer) and tells the LLM the file type (e.g., `audio/mpeg`, `audio/wav`).

This object matches the format Gemini expects for inline audio input.

**3. Sending the Prompt and Audio to the LLM**

```js
const result = await model([
    'Transcribe or analyze the following audio:',
    audioPart
]);
```
- The first array element is the **prompt** — here it’s a generic instruction to transcribe or analyse the audio.
- The second element is the **audio data object**.
- Passing both together allows the LLM to process the audio in the context of the prompt.

**4. Returning the Result**

```js
res.json({ output: result.text });
```
- The LLM’s response is returned to the client as JSON.
- `result.text` contains the transcription or analysis generated by the model.

 **5. Cleaning Up**

```js
if (filePath && fs.existsSync(filePath)) {
    fs.unlinkSync(filePath);
}
```
- After processing, the uploaded file is deleted from the server to save space and avoid clutter.

**6. Role of Multer**

Before this controller runs:
- **Multer** handles the file upload from the client.
- It saves the file to the `uploads/` folder.
- It adds file details (including `.path` and `.mimetype`) to `req.file`, which this controller uses.

**Why This Works**

- The LLM is **multimodal** — it can process both text and audio.
- By sending a **prompt** and the **audio data** together, we can:
  - Transcribe speech to text.
  - Analyse tone, sentiment, or content.
  - Extract key points or summaries.
  - Identify languages or speakers (depending on model capabilities).

---

## Additional Resources

- [Multer](https://www.npmjs.com/package/multer)
- [Text Generation Docs](https://ai.google.dev/gemini-api/docs/text-generation)  
- [Document Processing Docs](https://ai.google.dev/gemini-api/docs/document-processing)  
- [Image Understanding Docs](https://ai.google.dev/gemini-api/docs/image-understanding)  
- [Audio Processing Docs](https://ai.google.dev/gemini-api/docs/audio)  
- [Structured Output Docs](https://ai.google.dev/gemini-api/docs/structured-output)  


